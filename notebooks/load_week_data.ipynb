{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae10df7",
   "metadata": {},
   "source": [
    "### Data loader\n",
    "\n",
    "This function loads a few weeks of the dataset, keeps only the useful columns, stitches all weeks together, and attaches the play context to both input and output frames so we can immediately compute features and our five pillars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9d38013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_weeks_pandas(weeks, base=\"../data\"):\n",
    "    use_in = [\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\",\n",
    "              \"player_name\",\"player_position\",\"player_role\",\"player_side\",\n",
    "              \"x\",\"y\",\"s\",\"a\",\"o\",\"dir\",\n",
    "              \"num_frames_output\",\"ball_land_x\",\"ball_land_y\"]\n",
    "    use_out = [\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\",\"x\",\"y\"]\n",
    "    supp_cols = [\"game_id\",\"play_id\",\"season\",\"week\",\"pass_result\",\n",
    "                 \"team_coverage_man_zone\",\"pass_length\",\"route_of_targeted_receiver\",\n",
    "                 \"yards_gained\",\"expected_points\",\"expected_points_added\"]\n",
    "\n",
    "    inputs  = [pd.read_csv(f\"{base}/input_2023_w{w:02d}.csv\", usecols=use_in)  for w in weeks]\n",
    "    outputs = [pd.read_csv(f\"{base}/output_2023_w{w:02d}.csv\", usecols=use_out) for w in weeks]\n",
    "\n",
    "    input_df  = pd.concat(inputs,  ignore_index=True)\n",
    "    output_df = pd.concat(outputs, ignore_index=True)\n",
    "    supp_df   = pd.read_csv(f\"{base}/supplementary_data.csv\", usecols=supp_cols)\n",
    "\n",
    "    # join play context into input/output\n",
    "    input_df  = input_df.merge(supp_df,  on=[\"game_id\",\"play_id\"], how=\"left\")\n",
    "    output_df = output_df.merge(supp_df, on=[\"game_id\",\"play_id\"], how=\"left\")\n",
    "    \n",
    "    # filter 1 sec before throw for input df and 1 second before end of play for output df\n",
    "    # compute throw/catch frames per player\n",
    "    throw_frames = (\n",
    "        input_df.groupby([\"game_id\",\"play_id\",\"nfl_id\"])[\"frame_id\"]\n",
    "        .max()\n",
    "        .rename(\"throw_frame\")\n",
    "    )\n",
    "\n",
    "    end_frames = (\n",
    "        input_df.groupby([\"game_id\",\"play_id\",\"nfl_id\"])[\"num_frames_output\"]\n",
    "        .max()\n",
    "        .rename(\"end_frame\")\n",
    "    )\n",
    "\n",
    "    # Merge throw/catch frames into input/output\n",
    "    input_df  = input_df.merge(throw_frames, on=[\"game_id\",\"play_id\",\"nfl_id\"], how=\"left\")\n",
    "    output_df = output_df.merge(end_frames, on=[\"game_id\",\"play_id\",\"nfl_id\"], how=\"left\")\n",
    "\n",
    "    # Filter frames 1 second (10 frames) before the ball is thrown\n",
    "    input_df = input_df[\n",
    "        (input_df[\"frame_id\"] >= input_df[\"throw_frame\"] - 10)\n",
    "    ]\n",
    "    \n",
    "    # Filter frames 1 second (10 frames) before the end of the play\n",
    "    output_df = output_df[\n",
    "        (output_df[\"frame_id\"] >= output_df[\"end_frame\"] - 10)\n",
    "    ]\n",
    "    \n",
    "    #filtering players so its only WR and CB\n",
    "    input_df = input_df[(input_df.get('player_position') == 'WR') | (input_df.get('player_position') == 'CB')]\n",
    "\n",
    "    output_df = output_df[output_df['nfl_id'].isin(input_df['nfl_id'])]\n",
    "\n",
    "    #dropping unneccesary columns\n",
    "    input_df = input_df.drop(columns=['player_name'])\n",
    "\n",
    "    return input_df, output_df, supp_df\n",
    "\n",
    "# Example:\n",
    "# inp, out, supp = load_weeks_pandas([1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66ce5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, out, supp = load_weeks_pandas([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c42ca",
   "metadata": {},
   "source": [
    "<h2> Validating Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94e78c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== NFL Big Data Bowl Validation Report =====\n",
      "Validation completed.\n",
      "Input rows: 150,017, Output rows: 39,162\n",
      "Duplicate keys (input/output): 0/0\n",
      "Play match (input/output): 100.0% / 100.0%\n",
      "NFL ID overlap: 99.03%\n",
      "Invalid positions found: 0\n",
      "\n",
      "\n",
      "-- Nulls (Input) --\n",
      "{}\n",
      "\n",
      "-- Nulls (Output) --\n",
      "{}\n",
      "\n",
      "-- Frame range (input): (1, 83)\n",
      "-- X range: (np.float64(1.21), np.float64(119.86))\n",
      "-- Y range: (np.float64(0.72), np.float64(52.84))\n",
      "\n",
      "-- Frames per play summary --\n",
      "{'count': 2570.0, 'mean': 58.37, 'std': 10.69, 'min': 22.0, '25%': 55.0, '50%': 55.0, '75%': 66.0, 'max': 99.0}\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "def validate_join_and_integrity(input_df, output_df, supp_df):\n",
    "    report = {}\n",
    "\n",
    "    #Row counts\n",
    "    report[\"input_rows\"] = len(input_df)\n",
    "    report[\"output_rows\"] = len(output_df)\n",
    "    report[\"supp_rows\"] = len(supp_df)\n",
    "\n",
    "    #Column consistency\n",
    "    report[\"input_columns\"] = list(input_df.columns)\n",
    "    report[\"output_columns\"] = list(output_df.columns)\n",
    "\n",
    "    #Missing values\n",
    "    input_nulls = input_df.isna().mean().round(3)\n",
    "    output_nulls = output_df.isna().mean().round(3)\n",
    "    report[\"top_nulls_input\"] = input_nulls[input_nulls > 0].sort_values(ascending=False).head(10).to_dict()\n",
    "    report[\"top_nulls_output\"] = output_nulls[output_nulls > 0].sort_values(ascending=False).head(10).to_dict()\n",
    "\n",
    "    #Key uniqueness checks\n",
    "    key_input = input_df[['game_id','play_id','nfl_id','frame_id']]\n",
    "    key_output = output_df[['game_id','play_id','nfl_id','frame_id']]\n",
    "    report[\"duplicate_keys_input\"] = key_input.duplicated().sum()\n",
    "    report[\"duplicate_keys_output\"] = key_output.duplicated().sum()\n",
    "\n",
    "    #Referential integrity (plays in input/output exist in supp)\n",
    "    input_play_match = input_df['play_id'].isin(supp_df['play_id']).mean()\n",
    "    output_play_match = output_df['play_id'].isin(supp_df['play_id']).mean()\n",
    "    report[\"input_play_match_%\"] = round(100 * input_play_match, 2)\n",
    "    report[\"output_play_match_%\"] = round(100 * output_play_match, 2)\n",
    "\n",
    "    #WR/CB only check\n",
    "    valid_positions = {\"WR\", \"CB\"}\n",
    "    invalid_positions = set(input_df['player_position'].unique()) - valid_positions\n",
    "    report[\"invalid_positions_in_input\"] = list(invalid_positions)\n",
    "\n",
    "    #NFL IDs overlap check (input vs output)\n",
    "    overlap_ratio = input_df['nfl_id'].isin(output_df['nfl_id']).mean()\n",
    "    report[\"nfl_id_overlap_%\"] = round(100 * overlap_ratio, 2)\n",
    "\n",
    "    #Frame sanity check\n",
    "    min_frame = input_df['frame_id'].min()\n",
    "    max_frame = input_df['frame_id'].max()\n",
    "    report[\"frame_range_input\"] = (int(min_frame), int(max_frame))\n",
    "\n",
    "    #Coordinate sanity check\n",
    "    report[\"x_range_input\"] = (input_df['x'].min(), input_df['x'].max())\n",
    "    report[\"y_range_input\"] = (input_df['y'].min(), input_df['y'].max())\n",
    "\n",
    "    #Explosion detection (duplicate plays/frames)\n",
    "    play_counts = input_df.groupby(['game_id','play_id']).size().describe().to_dict()\n",
    "    report[\"frames_per_play_summary\"] = {k: round(v,2) for k,v in play_counts.items()}\n",
    "\n",
    "    #Summary message\n",
    "    report[\"summary\"] = (\n",
    "        f\"Validation completed.\\n\"\n",
    "        f\"Input rows: {report['input_rows']:,}, Output rows: {report['output_rows']:,}\\n\"\n",
    "        f\"Duplicate keys (input/output): {report['duplicate_keys_input']}/{report['duplicate_keys_output']}\\n\"\n",
    "        f\"Play match (input/output): {report['input_play_match_%']}% / {report['output_play_match_%']}%\\n\"\n",
    "        f\"NFL ID overlap: {report['nfl_id_overlap_%']}%\\n\"\n",
    "        f\"Invalid positions found: {len(report['invalid_positions_in_input'])}\\n\"\n",
    "    )\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "def print_validation_report(report):\n",
    "    print(\"===== NFL Big Data Bowl Validation Report =====\")\n",
    "    print(report[\"summary\"])\n",
    "    print(\"\\n-- Nulls (Input) --\")\n",
    "    print(report[\"top_nulls_input\"])\n",
    "    print(\"\\n-- Nulls (Output) --\")\n",
    "    print(report[\"top_nulls_output\"])\n",
    "    print(\"\\n-- Frame range (input):\", report[\"frame_range_input\"])\n",
    "    print(\"-- X range:\", report[\"x_range_input\"])\n",
    "    print(\"-- Y range:\", report[\"y_range_input\"])\n",
    "    print(\"\\n-- Frames per play summary --\")\n",
    "    print(report[\"frames_per_play_summary\"])\n",
    "    if report[\"invalid_positions_in_input\"]:\n",
    "        print(\"\\n Invalid positions present:\", report[\"invalid_positions_in_input\"])\n",
    "    print(\"=================================================\")\n",
    "    \n",
    "\n",
    "#Running report shows us the data integrity status, which in this case is good! No duplicates,\n",
    "#and data looks good.\n",
    "report = validate_join_and_integrity(inp, out, supp)\n",
    "print_validation_report(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
