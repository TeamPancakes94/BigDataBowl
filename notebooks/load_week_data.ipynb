{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae10df7",
   "metadata": {},
   "source": [
    "### Data loader\n",
    "\n",
    "This function loads a few weeks of the dataset, keeps only the useful columns, stitches all weeks together, and attaches the play context to both input and output frames so we can immediately compute features and our five pillars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d38013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_weeks_pandas(weeks, base=\"../data\"):\n",
    "    use_in = [\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\",\n",
    "              \"player_name\",\"player_position\",\"player_role\",\"player_side\",\n",
    "              \"x\",\"y\",\"s\",\"a\",\"o\",\"dir\",\n",
    "              \"num_frames_output\",\"ball_land_x\",\"ball_land_y\"]\n",
    "    use_out = [\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\",\"x\",\"y\"]\n",
    "    supp_cols = [\"game_id\",\"play_id\",\"season\",\"week\",\"pass_result\",\n",
    "                 \"team_coverage_man_zone\",\"pass_length\",\"route_of_targeted_receiver\",\n",
    "                 \"yards_gained\",\"expected_points\",\"expected_points_added\"]\n",
    "\n",
    "    inputs  = [pd.read_csv(f\"{base}/input_2023_w{w:02d}.csv\", usecols=use_in)  for w in weeks]\n",
    "    outputs = [pd.read_csv(f\"{base}/output_2023_w{w:02d}.csv\", usecols=use_out) for w in weeks]\n",
    "\n",
    "    input_df  = pd.concat(inputs,  ignore_index=True)\n",
    "    output_df = pd.concat(outputs, ignore_index=True)\n",
    "    supp_df   = pd.read_csv(f\"{base}/supplementary_data.csv\", usecols=supp_cols)\n",
    "\n",
    "    # join play context into input/output\n",
    "    input_df  = input_df.merge(supp_df,  on=[\"game_id\",\"play_id\"], how=\"left\")\n",
    "    output_df = output_df.merge(supp_df, on=[\"game_id\",\"play_id\"], how=\"left\")\n",
    "    #Get only the first and last frames\n",
    "    input_df = (\n",
    "        input_df.sort_values(['play_id', 'nfl_id', 'frame_id'])\n",
    "                .groupby(['play_id', 'nfl_id'], group_keys=False)\n",
    "                .apply(lambda g: g.loc[g['frame_id'].isin([g['frame_id'].min(), g['frame_id'].max()])]).reset_index()\n",
    "    )\n",
    "    output_df = (\n",
    "        output_df.sort_values(['play_id', 'nfl_id', 'frame_id'])\n",
    "                .groupby(['play_id', 'nfl_id'], group_keys=False)\n",
    "                .apply(lambda g: g.loc[g['frame_id'].isin([g['frame_id'].min(), g['frame_id'].max()])]).reset_index()\n",
    "    )\n",
    "    \n",
    "    #filtering players so its only WR and CB\n",
    "    input_df = input_df[(input_df.get('player_position') == 'WR') | (input_df.get('player_position') == 'CB')]\n",
    "\n",
    "    output_df = output_df[output_df['nfl_id'].isin(input_df['nfl_id'])]\n",
    "\n",
    "    #dropping unneccesary columns\n",
    "    input_df = input_df.drop(columns=['index', 'player_name'])\n",
    "    output_df = output_df.drop(columns=['index'])\n",
    "\n",
    "    return input_df, output_df, supp_df\n",
    "\n",
    "# Example:\n",
    "# inp, out, supp = load_weeks_pandas([1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ce5381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/hdz0102s321cbt41brs_8r040000gn/T/ipykernel_90998/3892070321.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.loc[g['frame_id'].isin([g['frame_id'].min(), g['frame_id'].max()])]).reset_index()\n",
      "/var/folders/dg/hdz0102s321cbt41brs_8r040000gn/T/ipykernel_90998/3892070321.py:33: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.loc[g['frame_id'].isin([g['frame_id'].min(), g['frame_id'].max()])]).reset_index()\n"
     ]
    }
   ],
   "source": [
    "inp, out, supp = load_weeks_pandas([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c42ca",
   "metadata": {},
   "source": [
    "<h2> Validating Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e78c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== NFL Big Data Bowl Validation Report =====\n",
      "Validation completed.\n",
      "Input rows: 27,221, Output rows: 7,968\n",
      "Duplicate keys (input/output): 0/0\n",
      "Play match (input/output): 100.0% / 100.0%\n",
      "NFL ID overlap: 99.03%\n",
      "Invalid positions found: 0\n",
      "\n",
      "\n",
      "-- Nulls (Input) --\n",
      "{}\n",
      "\n",
      "-- Nulls (Output) --\n",
      "{}\n",
      "\n",
      "-- Frame range (input): (1, 83)\n",
      "-- X range: (np.float64(1.21), np.float64(119.86))\n",
      "-- Y range: (np.float64(0.8), np.float64(52.87))\n",
      "\n",
      "-- Frames per play summary --\n",
      "{'count': 2570.0, 'mean': 10.59, 'std': 1.95, 'min': 4.0, '25%': 10.0, '50%': 10.0, '75%': 12.0, 'max': 18.0}\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "def validate_join_and_integrity(input_df, output_df, supp_df):\n",
    "    report = {}\n",
    "\n",
    "    #Row counts\n",
    "    report[\"input_rows\"] = len(input_df)\n",
    "    report[\"output_rows\"] = len(output_df)\n",
    "    report[\"supp_rows\"] = len(supp_df)\n",
    "\n",
    "    #Column consistency\n",
    "    report[\"input_columns\"] = list(input_df.columns)\n",
    "    report[\"output_columns\"] = list(output_df.columns)\n",
    "\n",
    "    #Missing values\n",
    "    input_nulls = input_df.isna().mean().round(3)\n",
    "    output_nulls = output_df.isna().mean().round(3)\n",
    "    report[\"top_nulls_input\"] = input_nulls[input_nulls > 0].sort_values(ascending=False).head(10).to_dict()\n",
    "    report[\"top_nulls_output\"] = output_nulls[output_nulls > 0].sort_values(ascending=False).head(10).to_dict()\n",
    "\n",
    "    #Key uniqueness checks\n",
    "    key_input = input_df[['game_id','play_id','nfl_id','frame_id']]\n",
    "    key_output = output_df[['game_id','play_id','nfl_id','frame_id']]\n",
    "    report[\"duplicate_keys_input\"] = key_input.duplicated().sum()\n",
    "    report[\"duplicate_keys_output\"] = key_output.duplicated().sum()\n",
    "\n",
    "    #Referential integrity (plays in input/output exist in supp)\n",
    "    input_play_match = input_df['play_id'].isin(supp_df['play_id']).mean()\n",
    "    output_play_match = output_df['play_id'].isin(supp_df['play_id']).mean()\n",
    "    report[\"input_play_match_%\"] = round(100 * input_play_match, 2)\n",
    "    report[\"output_play_match_%\"] = round(100 * output_play_match, 2)\n",
    "\n",
    "    #WR/CB only check\n",
    "    valid_positions = {\"WR\", \"CB\"}\n",
    "    invalid_positions = set(input_df['player_position'].unique()) - valid_positions\n",
    "    report[\"invalid_positions_in_input\"] = list(invalid_positions)\n",
    "\n",
    "    #NFL IDs overlap check (input vs output)\n",
    "    overlap_ratio = input_df['nfl_id'].isin(output_df['nfl_id']).mean()\n",
    "    report[\"nfl_id_overlap_%\"] = round(100 * overlap_ratio, 2)\n",
    "\n",
    "    #Frame sanity check\n",
    "    min_frame = input_df['frame_id'].min()\n",
    "    max_frame = input_df['frame_id'].max()\n",
    "    report[\"frame_range_input\"] = (int(min_frame), int(max_frame))\n",
    "\n",
    "    #Coordinate sanity check\n",
    "    report[\"x_range_input\"] = (input_df['x'].min(), input_df['x'].max())\n",
    "    report[\"y_range_input\"] = (input_df['y'].min(), input_df['y'].max())\n",
    "\n",
    "    #Explosion detection (duplicate plays/frames)\n",
    "    play_counts = input_df.groupby(['game_id','play_id']).size().describe().to_dict()\n",
    "    report[\"frames_per_play_summary\"] = {k: round(v,2) for k,v in play_counts.items()}\n",
    "\n",
    "    #Summary message\n",
    "    report[\"summary\"] = (\n",
    "        f\"Validation completed.\\n\"\n",
    "        f\"Input rows: {report['input_rows']:,}, Output rows: {report['output_rows']:,}\\n\"\n",
    "        f\"Duplicate keys (input/output): {report['duplicate_keys_input']}/{report['duplicate_keys_output']}\\n\"\n",
    "        f\"Play match (input/output): {report['input_play_match_%']}% / {report['output_play_match_%']}%\\n\"\n",
    "        f\"NFL ID overlap: {report['nfl_id_overlap_%']}%\\n\"\n",
    "        f\"Invalid positions found: {len(report['invalid_positions_in_input'])}\\n\"\n",
    "    )\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "def print_validation_report(report):\n",
    "    print(\"===== NFL Big Data Bowl Validation Report =====\")\n",
    "    print(report[\"summary\"])\n",
    "    print(\"\\n-- Nulls (Input) --\")\n",
    "    print(report[\"top_nulls_input\"])\n",
    "    print(\"\\n-- Nulls (Output) --\")\n",
    "    print(report[\"top_nulls_output\"])\n",
    "    print(\"\\n-- Frame range (input):\", report[\"frame_range_input\"])\n",
    "    print(\"-- X range:\", report[\"x_range_input\"])\n",
    "    print(\"-- Y range:\", report[\"y_range_input\"])\n",
    "    print(\"\\n-- Frames per play summary --\")\n",
    "    print(report[\"frames_per_play_summary\"])\n",
    "    if report[\"invalid_positions_in_input\"]:\n",
    "        print(\"\\n Invalid positions present:\", report[\"invalid_positions_in_input\"])\n",
    "    print(\"=================================================\")\n",
    "    \n",
    "\n",
    "#Running report shows us the data integrity status, which in this case is good! No duplicates,\n",
    "#and data looks good.\n",
    "report = validate_join_and_integrity(inp, out, supp)\n",
    "print_validation_report(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
